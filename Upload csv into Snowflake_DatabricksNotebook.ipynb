{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35d5a4b9-1456-42ba-9036-63ce188d2d85",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>s3://mibucketdecargasnowflakedani/credentials/snowflake.json</td><td>snowflake.json</td><td>45</td><td>1746167030000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "s3://mibucketdecargasnowflakedani/credentials/snowflake.json",
         "snowflake.json",
         45,
         1746167030000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pip install --upgrade snowflake-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b4ff1a9e-b2df-48f2-bdd9-95a1e7b5d8bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    " %restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d812527-10f1-4e61-8bc9-858314b2f7f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n|TEST_CONNECTION|\n+---------------+\n|              1|\n+---------------+\n\nConectado\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json_str = dbutils.fs.head(\"s3://mibucketdecargasnowflakedani/credentials/snowflake.json\", 4096)\n",
    "creds = json.loads(json_str)\n",
    "\n",
    "sfOptions = {\n",
    "  \"sfURL\"       : \"lnwnuwk-uf09760.snowflakecomputing.com\",\n",
    "  \"sfUser\"      : creds[\"user\"],\n",
    "  \"sfPassword\"  : creds[\"password\"],\n",
    "  \"sfDatabase\"  : \"KAGGLE_DB\",\n",
    "  \"sfSchema\"    : \"BRONZE\",\n",
    "  \"sfWarehouse\" : \"NEWS_WH\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    test_df = (\n",
    "        spark.read\n",
    "             .format(\"snowflake\")\n",
    "             .options(**sfOptions)\n",
    "             .option(\"query\", \"SELECT 1 AS test_connection\")\n",
    "             .load()\n",
    "    )\n",
    "    test_df.show()\n",
    "    print(\"Conectado\")\n",
    "except Exception as e:\n",
    "    print(\"Error:\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7f017ba-d432-4240-b7b8-bb5da55ab11c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workspace.bronze.assessments creada\nworkspace.bronze.courses creada\nworkspace.bronze.studentAssessment creada\nworkspace.bronze.studentInfo creada\nworkspace.bronze.studentRegistration creada\nworkspace.bronze.studentVle creada\nworkspace.bronze.vle creada\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "volume_path = \"/Volumes/workspace/bronze/volumecsv\"\n",
    "\n",
    "# Obtener lista de ficheros\n",
    "files = [f.path for f in dbutils.fs.ls(volume_path) if f.name.lower().endswith(\".csv\")]\n",
    "\n",
    "# Recorrer lista de ficheros\n",
    "for path in files:\n",
    "    # Extraer nombre de fichero\n",
    "    fname = path.split(\"/\")[-1]\n",
    "    table_name = fname.rsplit(\".\",1)[0]\n",
    "    \n",
    "    # Leer CSV\n",
    "    df = (\n",
    "        spark.read\n",
    "             .option(\"header\", \"true\")\n",
    "             .option(\"inferSchema\", \"true\")\n",
    "             .csv(path)\n",
    "    )\n",
    "    \n",
    "    # Guardar en tabla\n",
    "    (\n",
    "        df.write\n",
    "          .format(\"delta\")\n",
    "          .mode(\"overwrite\")\n",
    "          .option(\"overwriteSchema\", \"true\")\n",
    "          .saveAsTable(f\"workspace.bronze.{table_name}\")\n",
    "    )\n",
    "    print(f\"workspace.bronze.{table_name} creada\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a75e9ef-d493-47fb-a595-28176e8d6874",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRONZE.ASSESSMENTS existe\nassessments → BRONZE.ASSESSMENTS: 206 filas cargadas\nBRONZE.COURSES existe\ncourses → BRONZE.COURSES: 22 filas cargadas\nBRONZE.STUDENT_ASSESSMENT existe\nstudent_assessment → BRONZE.STUDENT_ASSESSMENT: 173912 filas cargadas\nBRONZE.STUDENT_INFO existe\nstudent_info → BRONZE.STUDENT_INFO: 32593 filas cargadas\nBRONZE.STUDENT_REGISTRATION existe\nstudent_registration → BRONZE.STUDENT_REGISTRATION: 32593 filas cargadas\nBRONZE.STUDENT_VLE existe\nstudent_vle → BRONZE.STUDENT_VLE: 10655280 filas cargadas\nBRONZE.VLE existe\nvle → BRONZE.VLE: 6364 filas cargadas\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import snowflake.connector\n",
    "from snowflake.connector.pandas_tools import write_pandas\n",
    "\n",
    "# Carga credenciales desde bucket\n",
    "json_str = dbutils.fs.head(\"s3://mibucketdecargasnowflakedani/credentials/snowflake.json\", 4096)\n",
    "creds    = json.loads(json_str)\n",
    "\n",
    "# Conexión a Snowflake\n",
    "cx = snowflake.connector.connect(\n",
    "    user=creds[\"user\"],\n",
    "    password=creds[\"password\"],\n",
    "    account=\"lnwnuwk-uf09760\",\n",
    "    warehouse=\"NEWS_WH\",\n",
    "    database=\"KAGGLE_DB\",\n",
    "    schema=\"BRONZE\"\n",
    ")\n",
    "cur = cx.cursor()\n",
    "\n",
    "# Listar tablas de workspace.bronze\n",
    "tables = spark.sql(\"SHOW TABLES IN `workspace`.`bronze`\").collect()\n",
    "\n",
    "for row in tables:\n",
    "    table_name    = row.tableName\n",
    "    snowflake_tbl = table_name.upper()\n",
    "\n",
    "    # Leer con Spark y pasar a Pandas\n",
    "    sdf = spark.table(f\"workspace.bronze.{table_name}\")\n",
    "    pdf = sdf.toPandas()\n",
    "\n",
    "    # Generar DDL CREATE TABLE si no existe\n",
    "    col_defs = []\n",
    "    for col, dtype in pdf.dtypes.items():\n",
    "        # mapeo\n",
    "        if pd.api.types.is_integer_dtype(dtype):\n",
    "            sf_type = \"NUMBER\"\n",
    "        elif pd.api.types.is_float_dtype(dtype):\n",
    "            sf_type = \"FLOAT\"\n",
    "        elif pd.api.types.is_bool_dtype(dtype):\n",
    "            sf_type = \"BOOLEAN\"\n",
    "        elif pd.api.types.is_datetime64_any_dtype(dtype):\n",
    "            sf_type = \"TIMESTAMP_NTZ\"\n",
    "        else:\n",
    "            sf_type = \"TEXT\"\n",
    "        col_defs.append(f'\"{col.upper()}\" {sf_type}')\n",
    "    ddl = f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS KAGGLE_DB.BRONZE.{snowflake_tbl} (\n",
    "            {', '.join(col_defs)}\n",
    "        )\n",
    "    \"\"\"\n",
    "    cur.execute(ddl)\n",
    "    print(f\"BRONZE.{snowflake_tbl} existe\")\n",
    "\n",
    "    # Volcar datos con write_pandas\n",
    "    success, nchunks, nrows, _ = write_pandas(\n",
    "        cx,\n",
    "        pdf,\n",
    "        table_name=snowflake_tbl,\n",
    "        schema=\"BRONZE\",\n",
    "        quote_identifiers=False\n",
    "    )\n",
    "    if success:\n",
    "        print(f\"{table_name} -> BRONZE.{snowflake_tbl}: {nrows} filas cargadas\")\n",
    "    else:\n",
    "        print(f\"Error cargando {table_name}\")\n",
    "\n",
    "cur.close()\n",
    "cx.close()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Upload csv into Snowflake",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}